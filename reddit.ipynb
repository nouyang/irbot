{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf8788a-fee4-40c4-80c7-704a5157aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b3f265-b26c-4476-8b22-9bdbe4c58e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit('irbot_readonly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7ed01c-3d50-4472-8baf-b2868ecdf0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529f4c6d-1b49-4907-87eb-1a4837486487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything Monday - Weekly Thread\n",
      "I still don't understand the benefit of lambda functions\n",
      "How do i get the content of a list to be print as just a string\n",
      "Today I discovered f strings and it made my day\n",
      "Convert Python Flask App to Standalone Desktiop Application\n",
      "why use __str__() method over str() function?\n",
      "Someone to learn python with by doing an ambitious project?\n",
      "Need resources to learn python programming as a beginner\n",
      "Recently started to deep dive into*algorithmic trading with Python + sharing what I've learned\n",
      "Python Programs not running in terminal?\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"learnpython\").hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f28ff-b361-43af-93f0-c065a997af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations: NOT update, title and tldr and question amrk, take out the age/sex modifiers?\n",
    "\n",
    "#relationship advice: the title and the question mark\n",
    "#maybe a sentence beore the question amrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec16ec7-08e8-41e1-9b75-722c11c22642",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Python Reddit API Wrapper (PRAW) was used to\n",
    "retrieve reddit data. Although [1] is already a high-quality\n",
    "source of life advice, the author chose to exercise caution and\n",
    "filter for top posts. Comments within the post were also sorted\n",
    "by ’top’. Also, posts are often very lengthy in comparison\n",
    "to comments. Since every post has a mandatory tl;dr (”too\n",
    "long didn’t read”, in other words a short summary), a regex\n",
    "was used to extract everything after ”tl;dr”. To provide more\n",
    "of a ”chatbot” style dataset, both the ”top-level” comments\n",
    "and then the replies to these comments were also recorded.\n",
    "This ultimately resulted in a 16.5 MB plaintext file, with\n",
    "about 25k rows. Each row consisted of either a submisison-\n",
    "comment or commment-reply duo separated by tabs. This\n",
    "was done in order to mash it straight into the pytorch chatbot\n",
    "tutoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94438a54-41c2-480c-9b3f-e9d50ea9f73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update to the pettiest question ever\n",
      "UPDATE: Me [36 M] married to my Wife [36 F] 11 years, and I can't stop thinking about a girl I dated for 1 month 16 years ago.\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"relationships\").top(\"year\", limit=2):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b50e0a0-7fd3-41a9-a3ac-3138ffdde452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE: I (30F) caught my husband (31M) in an affair and I don’t know how to move forward.\n",
      "Update to the pettiest question ever\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"relationships\").top(limit=2):\n",
    "    print(submission.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "860da14a-28a9-4b9a-aa75-a1f13804a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m going though a breakup that has left me feeling lost and broken. This gives me so much hope for the future. Tomorrow morning my journey begins as I go talk to a therapist for the first time and begin the road to recovery. Thank you for being so strong and sharing your story so others may find their strength through you. You’re amazing.\n",
      "THIS MAKES ME SO HAPPY. GOOD FOR YOU, OP!! You rock.\n",
      "Yay!!!!!!!! Congrats!!!\n",
      "\n",
      "There's nothing like living alone in your own, perfect space, amirite??\n"
     ]
    }
   ],
   "source": [
    "for top_level_comment in submission.comments[:3]:\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3da793-ce4f-4631-90ba-0f4b24576d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "print(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8257fc4-5fdb-4db4-8046-dcee0de2d935",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Submission' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-55e3c627fc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/v3/lib/python3.8/site-packages/praw/models/reddit/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;34mf\"{self.__class__.__name__!r} object has no attribute {attribute!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Submission' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "submission.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e0ac4b-81fe-4ed4-b3cc-7821d5ffab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(submission.content_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6189c7fe-6e5d-46d1-b1ab-6133a8a02fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16030"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c283f88f-b59f-4d66-b08a-c2479edcbf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Original Post: https://www.reddit.com/r/relationships/comments/i7wkqu/i_30f_caught_my_husband_31m_in_an_affair_and_i/\\n\\nFirst of all, I just want to thank everyone here for the support I received following my first post back in August. At the time, it truly felt like my world was ending. It was important to me to make this update because I need to tell anyone who’s currently going through the same thing—IT GETS BETTER. You will get so much better. \\n\\nI had one conversation with my husband since everything happened—by his choice. It lasted maybe five minutes and was like talking to a robot. I know from others that he cries to people about how he ruined his life, but I have never once gotten an apology or the same show of regret. At this point, I don’t care. I know him and the other woman are still seeing each other and frankly, they deserve each other. Good for them. \\n\\nWhile I still feel angry occasionally, I no longer mourn what I once had. Instead, I’m so excited for the life I now get to live. I moved to a small walkable city and gave myself my dream apartment. It makes me so happy to see how I’ve decorated it and to just live in a cozy place instead of our old dreary house.  I was the breadwinner in our marriage, and he would make me feel awful about wanting to pay for nice meals or do fun things. Since moving here, I’ve done a ton of foodie fun stuff and don’t feel guilty. It’s so refreshing. \\n\\nI have dipped my toe into the dating pool again and had plenty of mediocre dates from dating apps. Recently, I found someone who I’ve really clicked with and am enjoying how appreciated and desired he’s made me feel.  It’s definitely early and we’re moving slow, but overall, dating has made me realize that I’m a catch who doesn’t have to settle. \\n\\nTherapy has done wonders and I’m so happy I immediately dove into it. My therapist is proud of me. I’m proud of me. I’ve stopped looking at being divorced as a failure. He failed—not me. I’m genuinely happy and excited to wake up each morning and no longer feel like this terrible weight is sitting on my chest. The holidays were surprisingly easy and I found myself so happy to spend time with my family without having to compromise anything. \\n\\nSo all in all, life is good and there’s so much of it ahead. Looking back, I can’t believe I wasted so much time thinking about how I could get him to come home. I’ve made my own home and my own happiness and that is worth so so much more. \\n\\nTLDR; Husband left me for another woman. He sucks, but things get better.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defaee9d-93bb-45e5-9729-c7629248b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb10d2df-4a92-41ce-a3a2-f637365b427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nrw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nrw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nrw/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55bee0bd-bb84-448f-be5a-9301b7813350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/\n",
    "# \n",
    "\n",
    "# a. Stemming: A technique that takes the word to its root form. It just removes suffixes from the words\n",
    "# b. Lemmatization: Takes the word to its root form called Lemma. It helps to bring words to their dictionary form. It is applied to nouns by default.\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    #sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    '''\n",
    "    # https://nickmccullum.com/clean-text-machine-learning-python/\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    '''\n",
    "    return \" \".join(filtered_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54f2ba91-035c-409c-82b4-f2bf43805937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(sentence):\n",
    "    #my_tokens = sentence.split()\n",
    "    re.findall(\"[\\w']+\", sentence)\n",
    "    print([token.translate(str.maketrans('', '', string.punctuation)) for token in my_tokens])\n",
    "    [token.lower() for token in my_tokens]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76dbfc88-1f22-4d7e-9db8-2a1b2cf29385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Original', 'Post', 'https', 'www', 'reddit', 'com', 'r', 'relationships', 'comments', 'lqpshq', 'me_36_m_married_to_my_wife_36_f_11_years_and_i', 'So', 'I', 'mentioned', 'to', 'my', 'wife', 'vaguely', 'that', 'I', 'was', 'having', 'a', 'bit', 'of', 'a', 'midlife', 'crisis', 'and', 'ruminating', 'on', 'my', 'past', 'a', 'bit', 'too', 'much', 'That', 'I', 'miss', 'how', 'I', 'was', 'physically', 'at', 'my', 'peak', 'in', 'college', 'She', 'said', 'she', 'is', 'also', 'having', 'a', 'bit', 'of', 'a', 'crisis', 'worried', 'about', 'longterm', 'health', 'and', 'missing', 'the', 'shape', 'she', 'was', 'in', 'before', 'kids', 'We', 'made', 'a', 'commitment', 'to', 'each', 'other', 'to', 'get', 'into', 'shape', 'and', 'have', 'changed', 'our', 'eating', 'habits', 'and', 'bought', 'a', 'treadmill', 'I', 'have', 'been', 'working', 'out', 'daily', 'and', 'my', 'rumination', 'issues', 'have', 'really', 'dwindled', 'We', 'also', 'planned', 'a', 'nice', 'vacation', 'and', 'a', 'few', 'get', 'togethers', 'with', 'frends', 'in', 'the', 'next', 'few', 'months', 'tl', 'dr', 'Told', 'wife', 'I', 'was', 'having', 'a', 'crisis', 'without', 'much', 'detail', 'We', 'are', 'making', 'strides', 'to', 'better', 'ourselves', 'and', 'each', 'other']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3929063ffc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselftext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-1cd047240f0e>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#my_tokens = sentence.split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\\w']+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "clean_text(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf0a98f8-51d1-413f-b549-d3d8449d0da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original post mentioned wife vaguely bit midlife crisis ruminating past bit much miss physically peak college said also bit crisis worried longterm health missing shape kids made commitment get shape changed eating habits bought treadmill working daily rumination issues really dwindled also planned nice vacation get togethers frends next months told wife crisis without much detail making strides better'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(submission.selftext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52f0e6-b670-4a2c-9153-10e28446808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cleanText']=df['Text'].map(lambda s:preprocess(s)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
